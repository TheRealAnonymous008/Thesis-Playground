{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import manenv\n",
    "from manenv.utils.product_utils import *\n",
    "from manenv.core.world import World\n",
    "from manenv.core.component import *\n",
    "from manenv.render_wrapper import RenderWrapper\n",
    "from manenv.core.product import *\n",
    "from manenv.core.effector import *\n",
    "\n",
    "import manenv.effectors as eff\n",
    "import manenv.components as cmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = World((3, 3))\n",
    "s = np.zeros((5, 5), dtype=np.int8)\n",
    "s[1][2] = 2\n",
    "s[1][1] = 2\n",
    "s[2][1] = 1\n",
    "s[3][1] = 1\n",
    "product = Product(s)\n",
    "world.place_component(make_vector(1, 1), cmp.Conveyor(\n",
    "    np.array([\n",
    "    [0, 0, 0],\n",
    "    [1, 0, -1],\n",
    "    [0, 0, 0]\n",
    "])))\n",
    "world.place_component(make_vector(2, 0), cmp.Conveyor(\n",
    "    np.array([\n",
    "    [0, -1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 0] \n",
    "])))\n",
    "world.place_component(make_vector(2, 1), cmp.Outport())\n",
    "\n",
    "grabber = eff.Grabber(make_vector(0, 2))\n",
    "buddy = eff.Grabber(make_vector(1, 3))\n",
    "welder = eff.Welder(make_vector(1, 2))\n",
    "transformer = eff.Transformer(1, 2, make_vector(2,  4))\n",
    "discard = eff.Acceptor(make_vector(1, 7))\n",
    "\n",
    "world.place_component(make_vector(1, 2), cmp.Spawner(product))\n",
    "assembler : cmp.Assembler = cmp.Assembler(make_vector(10, 10), [grabber, buddy, welder, discard])\n",
    "world.place_component(make_vector(1, 0), assembler)\n",
    "wrapper = RenderWrapper(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.reset()\n",
    "# assembler.place_in_inventory(product.copy())\n",
    "# assembler.place_in_inventory(product.copy())\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.GRAB_INVENTORY.value)\n",
    "# grabber.set_action(eff.GrabberActions.GRAB_INVENTORY.value)\n",
    "# buddy.set_action(eff.GrabberActions.GRAB_INVENTORY.value)\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.RELEASE.value)\n",
    "# buddy.set_action(eff.GrabberActions.RELEASE.value)\n",
    "# world.update()\n",
    "\n",
    "# welder.set_action(eff.WelderActions.WELD_EAST.value)\n",
    "# world.update()\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.GRAB.value)\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.MOVE_RIGHT.value)\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.RELEASE.value)\n",
    "# world.update()\n",
    "\n",
    "# transformer.set_action(eff.TransformerActions.TRANSFORM.value)\n",
    "# world.update()\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.MOVE_RIGHT.value)\n",
    "# world.update()\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.MOVE_RIGHT)\n",
    "# world.update()\n",
    "\n",
    "# grabber.set_action(eff.GrabberActions.MOVE_RIGHT)\n",
    "# world.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym Environment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manenv.gym_wrapper import MARLFactoryEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.reset()\n",
    "environment = MARLFactoryEnvironment(world)\n",
    "renderer = RenderWrapper(environment._world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.test import parallel_api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    parallel_api_test(environment, num_cycles=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# cProfile.run('test()', sort = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manenv.solution.train_agents import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on factory.\n",
      "Using cuda device\n",
      "95\n",
      "96\n",
      "97\n",
      "99\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\Desktop\\Thesis-Playground\\manenv\\solution\\train_agents.py:31\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(env, games, seed)\u001b[0m\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m     24\u001b[0m     MultiInputPolicy,\n\u001b[0;32m     25\u001b[0m     env,\n\u001b[0;32m     26\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     27\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m steps \u001b[38;5;241m=\u001b[39m games \u001b[38;5;241m*\u001b[39m MARLFactoryEnvironment\u001b[38;5;241m.\u001b[39mMAX_GAME_STEPS\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has been saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\supersuit\\vector\\sb3_vector_wrapper.py:26\u001b[0m, in \u001b[0;36mSB3VecEnvWrapper.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 26\u001b[0m     observations, rewards, terminations, truncations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Note: SB3 expects dones to be an np.array\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m     29\u001b[0m         [terminations[i] \u001b[38;5;129;01mor\u001b[39;00m truncations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(terminations))]\n\u001b[0;32m     30\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\supersuit\\vector\\concat_vec_env.py:76\u001b[0m, in \u001b[0;36mConcatVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saved_actions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\supersuit\\vector\\concat_vec_env.py:84\u001b[0m, in \u001b[0;36mConcatVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m     81\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iterate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, actions))\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m venv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvec_envs:\n\u001b[0;32m     83\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m---> 84\u001b[0m         \u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m                \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m venv\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m     91\u001b[0m observations, rewards, terminations, truncations, infos \u001b[38;5;241m=\u001b[39m transpose(data)\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\supersuit\\vector\\markov_vector_wrapper.py:101\u001b[0m, in \u001b[0;36mMarkovVectorEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m     99\u001b[0m     reset_infs \u001b[38;5;241m=\u001b[39m [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39mpossible_agents))]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# combine standard infos and reset infos\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m infs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreset_inf\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_inf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_infs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblack_death \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39magents \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39mpossible_agents\n\u001b[0;32m    105\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarkovVectorEnv does not support environments with varying numbers of active agents unless black_death is set to True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observations, rews, tms, tcs, infs\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\thesis\\Lib\\site-packages\\supersuit\\vector\\markov_vector_wrapper.py:101\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     99\u001b[0m     reset_infs \u001b[38;5;241m=\u001b[39m [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39mpossible_agents))]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# combine standard infos and reset infos\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m infs \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreset_inf} \u001b[38;5;28;01mfor\u001b[39;00m inf, reset_inf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(infs, reset_infs)]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblack_death \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39magents \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpar_env\u001b[38;5;241m.\u001b[39mpossible_agents\n\u001b[0;32m    105\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarkovVectorEnv does not support environments with varying numbers of active agents unless black_death is set to True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observations, rews, tms, tcs, infs\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not a mapping"
     ]
    }
   ],
   "source": [
    "train_loop(environment, games=100, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
