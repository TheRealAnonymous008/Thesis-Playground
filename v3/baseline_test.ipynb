{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0764cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59353c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from use_case.baseline import * \n",
    "from tests.eval import *\n",
    "\n",
    "payoff_i = np.random.uniform(-10, 10, (10, 10))\n",
    "payoff_j = np.transpose(payoff_i).copy()\n",
    "\n",
    "# Initialize environment\n",
    "N_ACTIONS = payoff_i.shape[0]\n",
    "N_AGENTS = 1000\n",
    "env = BaselineEnvironment(N_AGENTS, payoff_i, payoff_j, total_games = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af11f7",
   "metadata": {},
   "source": [
    "# Actual Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3281f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import *\n",
    "from models.trainer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e4f52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the network here\n",
    "parameters = ParameterSettings(\n",
    "    n_agents = N_AGENTS,\n",
    "    d_action = N_ACTIONS, \n",
    "    d_obs = env.obs_size, \n",
    "    d_traits = 1,\n",
    "    d_beliefs = 1\n",
    ")\n",
    "parameters.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "109d0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8) 8.516185893985156\n",
      "(8, 3) 8.516185893985156\n"
     ]
    }
   ],
   "source": [
    "equilibriua = find_pure_equilibria(payoff_i, payoff_j)\n",
    "\n",
    "for eq in equilibriua:\n",
    "    x, y = eq \n",
    "    a = (y[0] + y[1]) / 2\n",
    "\n",
    "    print(x, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78db5dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Return: 3.2329091515115906\n",
      "Total returns: 32.329091515115906\n",
      "Action Dist, (array([  0,   0,   0,   0, 332,   0,   0, 668,   0,   0]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epock 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actor Loop:   4%|â–Ž         | 37/1000 [00:02<00:47, 20.40it/s]"
     ]
    }
   ],
   "source": [
    "# Setup the training loop\n",
    "training_parameters = TrainingParameters(\n",
    "    actor_training_loops = 1000, \n",
    "    outer_loops = 100,\n",
    "    learning_rate= 1e-3,\n",
    "    experience_buffer_size = 3\n",
    ")\n",
    "train_model(model, env, training_parameters)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
