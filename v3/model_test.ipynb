{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import *\n",
    "parameters = ParameterSettings()\n",
    "parameters.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9775, 0.9335, 0.2647,  ..., 0.2080, 0.5915, 0.5374],\n",
      "        [0.9216, 0.1446, 0.9384,  ..., 0.4736, 0.6774, 0.5878],\n",
      "        [0.4946, 0.9110, 0.3946,  ..., 0.2123, 0.7718, 0.9994],\n",
      "        ...,\n",
      "        [0.1175, 0.4216, 0.9133,  ..., 0.7227, 0.3405, 0.4519],\n",
      "        [0.5436, 0.5858, 0.1050,  ..., 0.1489, 0.8124, 0.4640],\n",
      "        [0.2893, 0.3613, 0.7100,  ..., 0.1559, 0.2104, 0.2467]],\n",
      "       device='cuda:0') tensor([[0.4751, 0.4561, 0.4560,  ..., 0.0499, 0.3307, 0.4459],\n",
      "        [0.1199, 0.9788, 0.5746,  ..., 0.9798, 0.7724, 0.3735],\n",
      "        [0.1806, 0.4023, 0.6209,  ..., 0.4793, 0.2839, 0.1070],\n",
      "        ...,\n",
      "        [0.3089, 0.7981, 0.0675,  ..., 0.9288, 0.7366, 0.4985],\n",
      "        [0.1892, 0.1563, 0.5384,  ..., 0.9828, 0.1302, 0.3770],\n",
      "        [0.8848, 0.4040, 0.0261,  ..., 0.2207, 0.4079, 0.3936]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sample agent\n",
    "agent_trait_vec = torch.rand((parameters.n_agents, parameters.d_traits), device=parameters.device)\n",
    "agent_belief_vec = torch.rand((parameters.n_agents, parameters.d_beliefs), device= parameters.device)\n",
    "\n",
    "print(agent_trait_vec, agent_belief_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, weights = model.hypernet.forward(agent_trait_vec, agent_belief_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vec = torch.rand((parameters.n_agents, parameters.d_obs), device=parameters.device)\n",
    "com_vec  = torch.rand((parameters.n_agents, parameters.d_comm_state), device=parameters.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_weights, b_weights, e_weights, f_weights, d_weights, u_weights = weights\n",
    "Q, h, ze = model.actor_encoder.forward(obs_vec, agent_belief_vec, com_vec, p_weights, b_weights, e_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for i in range(0, parameters.n_agents):\n",
    "    Mij = torch.rand((parameters.n_agents, parameters.d_relation), device=parameters.device)\n",
    "    weight = expand_weights(Mij.shape[0], i, f_weights)\n",
    "    message = model.filter.forward(ze[i], Mij, weight)\n",
    "    messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joaquin\\AppData\\Local\\Temp\\ipykernel_1728\\3507607844.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  message = torch.tensor(messages[i][0], device = parameters.device).reshape(1, -1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, parameters.n_agents):\n",
    "    message = torch.tensor(messages[i][0], device = parameters.device).reshape(1, -1)\n",
    "    Mij = torch.rand((1, parameters.d_relation), device=parameters.device)\n",
    "    d_weight = expand_weights(1, i, d_weights)\n",
    "\n",
    "    \n",
    "    umw, umb, usw, usb = u_weights\n",
    "    um_weights = umw, umb \n",
    "    us_weights = usw, usb \n",
    "\n",
    "    um_weight = expand_weights(1, i, um_weights)\n",
    "    us_weight = expand_weights(1, i, us_weights)\n",
    "\n",
    "    u_weight = *um_weight, *us_weight\n",
    "\n",
    "    zdj , Mip = model.decoder_update.forward(message, Mij, d_weight, u_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Hypernet: 7139936 \n",
      "        Actor Encoder: 213888 \n",
      "        Filter: 4736 \n",
      "        Decoder: 133440 \n",
      "        Total: 7492000\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "model.param_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
